{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "**Prerequisites:** This notebook requires additional packages for plotting and MCMC visualization. Install them with:\n",
    "```\n",
    "pip install matplotlib corner tqdm\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import corner\n",
    "from VegasAfterglow import ObsData, Setups, Fitter, ParamDef, Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### 1. PREPARE DATA #########\n",
    "#Create an instance of the ObsData class to store light curve and spectrum data\n",
    "data = ObsData()\n",
    "\n",
    "# Define the frequency bands [Hz] and corresponding light curve files\n",
    "band = [2.4e17, 4.84e14, 1.4e14]\n",
    "lc_files = [\"data/ep.csv\", \"data/r.csv\", \"data/vt-r.csv\"]\n",
    "\n",
    "# Loop through each frequency band and corresponding file(s)\n",
    "for nu, fname in zip(band, lc_files):\n",
    "    # Read the light curve data from the CSV file (columns: t, Fv_obs, Fv_err)\n",
    "    t_data, Fv_obs, Fv_err = np.loadtxt(fname, delimiter=',', skiprows=1, unpack=True)\n",
    "\n",
    "    # Add the light curve data to the 'data' object for the given frequency band\n",
    "    # You can assign weight to each data point for chi^2 evaluation\n",
    "    # You don't need to worry about the weights' normalization, the code will normalize them automatically.\n",
    "    data.add_flux_density(nu=nu, t=t_data, f_nu=Fv_obs, err=Fv_err, weights=np.ones(len(t_data)))  # All quantities in CGS units\n",
    "\n",
    "# Define the times [s] for spectra and corresponding files\n",
    "times = [3000]\n",
    "spec_files = [\"data/ep-spec.csv\"]    \n",
    "\n",
    "# Loop through each time and its corresponding spectrum file\n",
    "for t, fname in zip(times, spec_files):\n",
    "    # Read the spectrum data from the CSV file (columns: nu, Fv_obs, Fv_err)\n",
    "    nu_data, Fv_obs, Fv_err = np.loadtxt(fname, delimiter=',', skiprows=1, unpack=True)\n",
    "\n",
    "    # Add the spectrum data to the 'data' object for the given time\n",
    "    data.add_spectrum(t=t, nu=nu_data,\n",
    "                      f_nu=Fv_obs, err=Fv_err, weights=np.ones(len(nu_data)))  # All quantities in CGS units\n",
    "\n",
    "######### 2. CONFIGURE MODEL #########\n",
    "cfg = Setups()\n",
    "cfg.lumi_dist = 3.364e28    # Luminosity distance [cm]  \n",
    "cfg.z         = 1.58        # Redshift\n",
    "cfg.medium    = \"wind\"      # Medium type: \"wind\", \"ism\" (Interstellar Medium)\n",
    "cfg.jet       = \"powerlaw\"  # Jet structure: \"powerlaw\", \"gaussian\", \"tophat\", \"two_component\", \"step_powerlaw\" \n",
    "\n",
    "######### 3. DEFINE PARAMETERS #########\n",
    "# Parameter name, lower bound, upper bound, scale type, initial value (optional)\n",
    "\n",
    "mc_params = [\n",
    "    ParamDef(\"E_iso\",    1e51,  1e54,  Scale.LOG,    1e53),    # Isotropic energy [erg]\n",
    "    ParamDef(\"Gamma0\",      5,  1000,  Scale.LOG,      20),    # Lorentz factor at the core\n",
    "    ParamDef(\"theta_c\",   0.0,   0.5,  Scale.LINEAR,  0.3),    # Core half-opening angle [rad]\n",
    "    ParamDef(\"k_e\",         2,     2,  Scale.FIXED,     2),    # Energy power law index\n",
    "    ParamDef(\"k_g\",         2,     2,  Scale.FIXED,     2),    # Lorentz factor power law index\n",
    "    ParamDef(\"theta_v\",   0.0,   0.0,  Scale.FIXED,   0.0),    # Viewing angle [rad]\n",
    "    ParamDef(\"p\",           2,     3,  Scale.LINEAR,  2.3),    # Power law index\n",
    "    ParamDef(\"eps_e\",    1e-2,   0.3,  Scale.LOG,    0.05),    # Electron energy fraction\n",
    "    ParamDef(\"eps_B\",    1e-4,   0.3,  Scale.LOG,    0.03),    # Magnetic field energy fraction\n",
    "    ParamDef(\"xi_e\",     1e-3,   0.1,  Scale.LOG,    0.01),    # Electron acceleration efficiency\n",
    "    ParamDef(\"A_star\",   1e-3,    10,  Scale.LOG,    0.05),    # Wind parameter \n",
    "]\n",
    "\n",
    "######### 4. RUN MCMC SAMPLING #########\n",
    "# Create an instance of the Fitter class using the prepared data and configuration\n",
    "fitter = Fitter(data, cfg)\n",
    "\n",
    "# Run the fitting process using bilby with dynesty sampler\n",
    "#result = fitter.fit(\n",
    "#    mc_params,\n",
    "#    resolution=(0.3, 0.3, 10), # Grid resolution (phi, theta, t) - affects model accuracy\n",
    "#    sampler=\"dynesty\",         # Use dynesty nested sampler\n",
    "#    nlive=500,                 # Number of live points\n",
    "#    dlogz=0.1,                 # Stopping criterion\n",
    "#    top_k=10,                  # Number of best-fit parameters to return\n",
    "#    outdir=\"bilby_output\",     # Output directory for results\n",
    "#    label=\"afterglow_fit_dynesty\"    # Run label\n",
    "#)\n",
    "\n",
    "# Run the fitting process using bilby with emcee sampler\n",
    "result = fitter.fit(\n",
    "    mc_params,\n",
    "    resolution=(0.2, 0.3, 10),# Grid resolution (phi, theta, t) - affects model accuracy\n",
    "    sampler=\"emcee\",          # Use emcee MCMC sampler \n",
    "    nsteps=10000,             # Number of steps per walker \n",
    "    nburn=2000,               # Burn-in steps to discard\n",
    "    top_k=10,                 # Number of best-fit parameters to return\n",
    "    outdir=\"bilby_output\",    # Output directory for results#\n",
    "    label=\"afterglow_fit_emcee\"    # Run label##\n",
    ")\n",
    "\n",
    "print(f\"Total samples: {result.samples.shape[0]}\")\n",
    "\n",
    "# Print top-k parameters\n",
    "print(\"\\nTop-k parameters:\")\n",
    "header = f\"{'Rank':>4s}  {'chi^2':>10s}  \" + \"  \".join(f\"{name:>10s}\" for name in result.labels)\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "for i in range(result.top_k_params.shape[0]):\n",
    "    chi2 = -2 * result.top_k_log_probs[i]\n",
    "    vals = \"  \".join(f\"{val:10.4f}\" for val in result.top_k_params[i])\n",
    "    print(f\"{i+1:4d}  {chi2:10.2f}  {vals}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define time and frequency ranges for predictions\n",
    "t_out = np.logspace(2, 9, 150)\n",
    "\n",
    "nu_out = np.logspace(16,20,150)\n",
    "\n",
    "best_params = result.top_k_params[0]\n",
    "\n",
    "# Generate model light curves at the specified bands using the best-fit parameters\n",
    "lc = fitter.flux_density_grid(best_params, t_out, band)\n",
    "\n",
    "# Generate model spectra at the specified times using the best-fit parameters\n",
    "spec = fitter.flux_density_grid(best_params, times, nu_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot model light curves along with observed data\n",
    "def draw_bestfit(t,lc_fit, nu, spec_fit):\n",
    "    fig =plt.figure(figsize=(4.5, 7.5))\n",
    "    ax1 = fig.add_subplot(211)\n",
    "    ax2 = fig.add_subplot(212)\n",
    "\n",
    "    shift = [1,1,200]\n",
    "    colors = ['blue', 'orange', 'green']\n",
    "    for i, file, sft, c in zip(range(len(lc_files)), lc_files, shift, colors ):\n",
    "        t_d, Fv_d, Fe_d = np.loadtxt(file, delimiter=',', skiprows=1, unpack=True)\n",
    "        ax1.errorbar(t_d, Fv_d*sft, Fe_d*sft, fmt='o',markersize=4,label=file, color=c,markeredgecolor='k', markeredgewidth=.4)\n",
    "        ax1.plot(t, np.array(lc_fit[i,:])*sft, color=c,lw=1)\n",
    "\n",
    "    ax1.set_xscale('log')\n",
    "    ax1.set_yscale('log')\n",
    "    ax1.set_xlabel('t [s]')\n",
    "    ax1.set_ylabel(r'$F_\\nu$ [erg/cm$^2$/s/Hz]')\n",
    "    ax1.legend()\n",
    "  \n",
    "    for i, file, sft, c in zip(range(len(spec_files)), spec_files, shift, colors ):\n",
    "        nu_d, Fv_d, Fe_d = np.loadtxt(file, delimiter=',', skiprows=1, unpack=True)\n",
    "        ax2.errorbar(nu_d, Fv_d*sft, Fe_d*sft, fmt='o',markersize=4,label=file, color=c,markeredgecolor='k', markeredgewidth=.4)\n",
    "        ax2.plot(nu, np.array(spec_fit[:,i])*sft, color=c,lw=1)\n",
    "\n",
    "    ax2.set_xscale('log')\n",
    "    ax2.set_yscale('log')\n",
    "    ax2.set_xlabel(r'$\\nu$ [Hz]')\n",
    "    ax2.set_ylabel(r'$F_\\nu$ [erg/cm$^2$/s/Hz]')\n",
    "    ax2.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "draw_bestfit(t_out, lc, nu_out, spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### 5. VISUALIZATION #########\n",
    "\n",
    "# Option 1: Use bilby's built-in corner plot (recommended - uses proper LaTeX labels)\n",
    "# result.bilby_result.plot_corner()\n",
    "\n",
    "# Option 2: Custom corner plot using the corner package\n",
    "def plot_corner(flat_chain, labels, filename=\"corner_plot.png\"):\n",
    "    \"\"\"Create a corner plot showing parameter correlations and confidence intervals.\"\"\"\n",
    "    fig = corner.corner(\n",
    "        flat_chain,\n",
    "        labels=labels,\n",
    "        quantiles=[0.16, 0.5, 0.84],  \n",
    "        show_titles=True,\n",
    "        title_kwargs={\"fontsize\": 14},\n",
    "        label_kwargs={\"fontsize\": 14},\n",
    "        truths=np.median(flat_chain, axis=0),  # Show median values\n",
    "        truth_color='red',\n",
    "        smooth=1,\n",
    "        bins=30,\n",
    "        plot_datapoints=False,\n",
    "        fill_contours=True,\n",
    "        levels=[0.16, 0.5, 0.68],  \n",
    "        color='k',\n",
    "        alpha=0.5\n",
    "    )\n",
    "    for ax in fig.get_axes():\n",
    "        ax.tick_params(axis='both', labelsize=12) \n",
    "    fig.savefig(filename, dpi=600, bbox_inches='tight')\n",
    "    print(f\"Corner plot saved to: {filename}\")\n",
    "\n",
    "# Flatten the samples for corner plot\n",
    "# Note: For nested sampling, samples are weighted - this is a simplified version\n",
    "flat_chain = result.samples.reshape(-1, result.samples.shape[-1])\n",
    "\n",
    "# Create corner plot\n",
    "plot_corner(flat_chain, result.latex_labels, filename=\"corner_plot.png\")\n",
    "\n",
    "# For a more accurate weighted corner plot, use bilby's built-in method:\n",
    "# result.bilby_result.plot_corner(filename=\"corner_bilby.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
